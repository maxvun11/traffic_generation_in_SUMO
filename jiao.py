# -*- coding: utf-8 -*-
"""jiao

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C9d6nndzSr9A4CcorrCgDKeYuYuklkR6
"""

import numpy as np

# Valid routes (both clockwise and counter-clockwise)
valid_routes = [
    [ 0,  1,  2 ],
    [ 1,  2,  0 ],
    [ 2,  0,  1 ],
    [0, 2, 1 ],
    [1, 0, 2 ],
    [2, 1, 0 ]
]


#GAN 83.91
# generated_routes = [
#     [ 0.550,  1.585, -0.394],  # Route 1
#     [ 0.067, 2.085, 0.973],   # Route 2
#     [ 0.261,  1.174,  1.247],   # Route 3
#     [ 0.057,  0.982,  1.934],   # Route 4
#     [ 1.197,  2.243,  0.030],   # Route 5
#     [ 0.924,  2.002,  0.017],   # Route 6
#     [ 0.962,  1.998,  0.030],   # Route 7
#     [-0.157,  0.900,  1.797]    # Route 8
# ]

#GAN 88.93
# generated_routes = [
#     [ 0.059, 2.146, 1.076],  # Route 1
#     [ 0.187,  1.032,  1.865],   # Route 2
#     [-0.042, 2.065, 1.257],   # Route 3
#     [ 0.142,  1.061,  1.926],   # Route 4
#     [-0.093, 2.196, 1.182],   # Route 5
#     [2.228, 0.976,  0.264],   # Route 6
#     [ 1.051,  2.090, -0.050],   # Route 7
#     [ 1.093,  2.097,  0.012]    # Route 8
# ]


# gan 81.67
# generated_routes = [
#     [ 1.003,  2.004,  0.066],
#     [ 0.497,  0.398,  2.195],
#     [ 0.147,  1.041,  1.873],
#     [-0.114,  1.292,  1.772],
#     [-0.019,  1.964,  1.080],
#     [ 1.479,  0.280,  1.276],
#     [ 1.425,  1.630, -0.105],
#     [ 1.978, -0.048,  0.901]
# ]


# #wgan 84.78
# generated_routes = [
#     [0.0360, 1.2642, 1.7079, ],
#     [1.9664, 0.0858, 0.9097, ],
#     [0.1984, 2.0587, 0.7367, ],
#     [1.8947, 0.0301, 0.9575, ],
#     [-0.0254, 0.9738, 2.0610, ],
#     [2.0181, 0.0474, 0.9912, ],
#     [1.6996, 0.0617, 1.2820, ],
#     [1.4476, 0.9450, 0.7136, ]
# ]

#wgan 82.27
# generated_routes = [
#     [2.0721, 0.0707, 1.0684, ],
#     [1.9695, 0.5825, 0.4416, ],
#     [1.4233, 1.5125, 0.1258, ],
#     [0.0168, 1.3369, 1.5896, ],
#     [-0.0313, 1.0227, 1.9671, ],
#     [1.9010, 1.0703, -0.1389, ],
#     [1.9781, 0.0579, 1.1472, ],
#     [-0.0077, 1.4137, 1.6896, ]
# ]


# wgan 89.89
generated_routes = [
    [0.0882, 1.9689, 1.1145, ],
    [1.9803, 0.0301, 1.0115, ],
    [0.0104, 1.8227, 1.2692, ],
    [1.1431, 1.9129, 0.0128, ],
    [0.1127, 0.9207, 1.9768, ],
    [0.0114, 2.0290, 1.0600, ],
    [1.7514, 0.7790, 0.5251, ],
    [1.9998, 0.0770, 0.9560, ]
]

#wgan  87.52
generated_routes = [
    [-0.0014,  1.0650,  1.9270,  ],
    [ 1.9775,  0.3025,  0.7451,  ],
    [-0.0578,  2.0499,  0.9410, ],
    [ 1.8498,  0.1917,  0.8205,  ],
    [-0.0547,  0.9342,  2.0608, ],
    [ 2.0194,  0.1575,  0.9287,  ],
    [ 1.9243,  0.0007,  1.0408,  ],
    [ 1.5268,  1.0902,  0.4784,  ]
]

#wgan 84.75
# generated_routes = [
#     [-0.0003, 1.0985, 1.9888, ],
#     [ 1.9333, -0.0283, 1.1555,  ],
#     [ 1.6866,  0.0009, 1.4202,  ],
#     [ 1.1633,  1.0385, 0.8559, ],
#     [ 1.9485, -0.0239, 1.0679, ],
#     [ 0.0292,  2.1288, 0.9227,  ],
#     [ 1.9566,  1.1403, -0.0702,],
#     [ 0.0468,  2.0433, 0.8879, ]
# ]





def snap_route_to_valid(route):
    route = np.array(route)
    best_perm = None
    best_error = float('inf')
    for perm in valid_routes:
        perm = np.array(perm)
        error = np.mean(np.abs(route - perm))
        if error < best_error:
            best_perm = perm.tolist()
            best_error = error
    return best_perm

def calculate_route_accuracy(route):
    snapped = snap_route_to_valid(route)

    # Convert to numpy arrays for easier calculation
    route_arr = np.array(route)
    snapped_arr = np.array(snapped)

    # Calculate the numerator and denominator properly
    sum_diff = np.sum(np.abs(route_arr - snapped_arr))
    sum_snap = np.sum(np.abs(snapped_arr))

    if sum_snap == 0:
        accuracy_pct = 0.0
    else:
        accuracy_pct = ((sum_snap - sum_diff) / sum_snap) * 100.0

    # Ensure accuracy is within 0-100 bounds
    accuracy_pct = max(min(accuracy_pct, 100.0), 0.0)

    # Calculate MAE, RMSE, and sMAPE
    mae = np.mean(np.abs(route_arr - snapped_arr))
    rmse = np.sqrt(np.mean((route_arr - snapped_arr) ** 2))

    # sMAPE calculation with epsilon to avoid division by zero
    epsilon = 1e-6
    numerator = 2 * np.abs(route_arr - snapped_arr)
    denominator = np.abs(snapped_arr) + np.abs(route_arr) + epsilon
    smape = 100 * np.mean(numerator / denominator)

    return accuracy_pct, snapped, mae, rmse, smape


def interpret_smape(smape):
    if smape < 20:
        return "Excellent"
    elif smape < 50:
        return "Good"
    elif smape < 100:
        return "Moderate"
    else:
        return "High Error"

# Evaluate and print results
print("Route Evaluation Report:")
print("-----------------------")
for i, route in enumerate(generated_routes, 1):
    accuracy, snapped, mae, rmse, smape = calculate_route_accuracy(route)

    print(f"Route {i}:")
    print(f"  Generated: {[round(x, 4) for x in route]}")
    print(f"  Snapped:   {snapped}")
    print(f"  Accuracy:  {accuracy:.2f}%")
    print(f"  MAE:       {mae:.4f}")
    print(f"  RMSE:      {rmse:.4f}")
    print(f"  sMAPE:     {smape:.2f}% ({interpret_smape(smape)})")
    print()

# Calculate averages
accuracies = []
maes = []
rmses = []
smapes = []

for route in generated_routes:
    accuracy, _, mae, rmse, smape = calculate_route_accuracy(route)
    accuracies.append(accuracy)
    maes.append(mae)
    rmses.append(rmse)
    smapes.append(smape)

print("\nSummary Statistics:")
print("------------------")
print(f"Average Accuracy: {np.mean(accuracies):.2f}%")
print(f"Average MAE:      {np.mean(maes):.4f}")
print(f"Average RMSE:     {np.mean(rmses):.4f}")
print(f"Average sMAPE:    {np.mean(smapes):.2f}%")
print(f"\nBest sMAPE:       {min(smapes):.2f}%")
print(f"Worst sMAPE:      {max(smapes):.2f}%")

import matplotlib.pyplot as plt
import numpy as np

# ──────────────────────────────────────────────
# 1. TRIANGLE GEOMETRY
# ──────────────────────────────────────────────
nodes = {
    "J0": (0, 0),       # Bottom-left
    "J1": (300, 300),   # Top
    "J2": (600, 0)      # Bottom-right
}

def node_to_coordinate(v):
    """
    Map scalar value 'v' to (x, y) on triangle perimeter.
    Uses modulo-3 wrapping for triangle path segments.
    """
    v = v % 3
    if 0 <= v <= 1:
        t = v
        (x0, y0), (x1, y1) = nodes["J0"], nodes["J1"]
    elif 1 < v <= 2:
        t = v - 1
        (x0, y0), (x1, y1) = nodes["J1"], nodes["J2"]
    else:
        t = v - 2
        (x0, y0), (x1, y1) = nodes["J2"], nodes["J0"]
    x = x0 + (x1 - x0) * t
    y = y0 + (y1 - y0) * t
    return round(x, 2), round(y, 2)

# # ──────────────────────────────────────────────
# # 2. ROUTES (each with 3 scalar values)
# # ──────────────────────────────────────────────
routes = [
    [0.0882, 1.9689, 1.1145, ],
    [1.9803, 0.0301, 1.0115, ],

    [1.1431, 1.9129, 0.0128, ],
    [0.1127, 0.9207, 1.9768, ],
    [0.0114, 2.0290, 1.0600, ],

    [1.9998, 0.0770, 0.9560, ],

    [-0.0578,  2.0499,  0.9410, ],

    [ 1.9243,  0.0007,  1.0408,  ],

]


# ──────────────────────────────────────────────
# 3. PLOTTING
# ──────────────────────────────────────────────
plt.figure(figsize=(10, 10))

# Draw triangle perimeter
tri_x = [nodes["J0"][0], nodes["J1"][0], nodes["J2"][0], nodes["J0"][0]]
tri_y = [nodes["J0"][1], nodes["J1"][1], nodes["J2"][1], nodes["J0"][1]]
plt.plot(tri_x, tri_y, "k-", linewidth=3, label="Triangle Network")
plt.scatter(tri_x[:-1], tri_y[:-1], c="red", s=150, edgecolors="black", zorder=5, label="Corner Nodes (0,1,2)")

# Plot routes (3 points each)
colors = plt.cm.tab20(np.linspace(0, 1, len(routes)))
for i, route in enumerate(routes):
    coords = [node_to_coordinate(v) for v in route]
    x, y = zip(*coords)
    x, y = list(x) + [x[0]], list(y) + [y[0]]  # close the triangle loop

    plt.plot(x, y, 'o-', color=colors[i], lw=2.5, ms=8,
             markeredgecolor='black', label=f"Route {i+1}")

    for j in range(len(route)):
        dx, dy = x[j+1] - x[j], y[j+1] - y[j]
        plt.arrow(x[j], y[j], dx*0.8, dy*0.8, color=colors[i],
                  head_width=10, head_length=12, lw=0,
                  length_includes_head=True, shape="full")

# Final formatting
plt.title("3-Point Routes on Triangle Network", fontsize=14, pad=15)
plt.xlabel("X position")
plt.ylabel("Y position")
plt.legend(bbox_to_anchor=(1.02, 1), loc="upper left", fontsize=9)
plt.grid(True, linestyle="--", alpha=0.5)
plt.axis("equal")
plt.xlim(-100, 700)
plt.ylim(-350, 450)

# Add node value annotations
for i, node in enumerate(['J0 (0, 0)', 'J1 (300, 300)', 'J2 (600, 0)']):
    plt.annotate(node, (tri_x[i]+10, tri_y[i]+10), fontsize=12,
                bbox=dict(facecolor='white', alpha=0.8))

plt.tight_layout()
plt.show()

import torch, torch.nn as nn, torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np, random, time

# ░░ REPRODUCIBILITY ░░
torch.manual_seed(42); np.random.seed(42); random.seed(42)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Running on: {device}")

# ░░ DATASET ░░
base_routes = np.array([
    [ 0.0,  1.0,  2.0],
    [ 1.0,  2.0,  0.0],
    [ 2.0,  0.0,  1.0],
    [ 0.0, 2.0,1.0],
    [1.0,  0.0, 2.0],
    [2.0, 1.0,  0.0]
], dtype=np.float32)

# Expand and normalize to [-1, 1] (preserving signs)
valid_routes = np.tile(base_routes, (100, 1)) / 2.0
loader = DataLoader(
    TensorDataset(torch.tensor(valid_routes)),
    batch_size=16, shuffle=True, drop_last=False
)

# ░░ ARCHITECTURE ░░
z_dim, hidden, out_dim = 5, 128, 3

def weights_init(m):
    if isinstance(m, nn.Linear):
        nn.init.normal_(m.weight, 0.0, 0.02)
        nn.init.zeros_(m.bias)

class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(z_dim, hidden), nn.BatchNorm1d(hidden), nn.ReLU(True),
            nn.Linear(hidden, hidden), nn.BatchNorm1d(hidden), nn.ReLU(True),
            nn.Linear(hidden, out_dim)
        )
        self.apply(weights_init)
    def forward(self, z): return self.net(z)

class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(out_dim, hidden), nn.LeakyReLU(0.2, True),
            nn.Linear(hidden, hidden), nn.LeakyReLU(0.2, True),
            nn.Linear(hidden, 1)
        )
        self.apply(weights_init)
    def forward(self, x): return self.net(x).view(-1)

G, D = Generator().to(device), Discriminator().to(device)

# ░░ OPTIMIZATION ░░
criterion = nn.BCEWithLogitsLoss()
g_opt = optim.Adam(G.parameters(), lr=2e-4, betas=(0.0, 0.9))
d_opt = optim.Adam(D.parameters(), lr=1e-4, betas=(0.0, 0.9))

# ░░ TRAINING SETTINGS ░░
epochs = 50
k_d_steps = 1
start_sigma, end_sigma = 0.05, 0.0

# ░░ TRAINING LOOP ░░
for epoch in range(epochs):
    start = time.time()
    sigma = start_sigma + (end_sigma - start_sigma) * (epoch / epochs)

    for real_batch, in loader:
        real = real_batch.to(device)

        # ░ Train Discriminator ░
        for _ in range(k_d_steps):
            z = torch.randn(real.size(0), z_dim, device=device)
            fake = G(z).detach()
            noisy_real = real + sigma * torch.randn_like(real)
            noisy_fake = fake + sigma * torch.randn_like(fake)

            d_opt.zero_grad()
            real_lbl = torch.full((real.size(0),), 0.9, device=device)  # soft label
            fake_lbl = torch.zeros(real.size(0), device=device)

            loss_d = (criterion(D(noisy_real), real_lbl)
                    + criterion(D(noisy_fake), fake_lbl)) / 2
            loss_d.backward(); d_opt.step()

        # ░ Train Generator ░
        z = torch.randn(real.size(0), z_dim, device=device)
        fake = G(z)
        g_opt.zero_grad()
        g_target = torch.full((real.size(0),), 0.9, device=device)
        loss_g = criterion(D(fake), g_target)
        loss_g.backward(); g_opt.step()

    # ░ Logging every 200 epochs ░
    if epoch % 50 == 0:
        print(f"Epoch {epoch:>4} | D loss {loss_d.item():.4f} | G loss {loss_g.item():.4f} | Time: {time.time()-start:.2f}s")

# ░░ GENERATE ░░
with torch.no_grad():
    z = torch.randn(1000, z_dim, device=device)
    routes = G(z).cpu().numpy() * 2.0  # de-normalize back to [-2, 2]

# ░░ MATCHING FUNCTION THAT PRESERVES SIGN OF 0 ░░
def exact_vector_match(vec1, vec2):
    return np.allclose(vec1, vec2, atol=1e-3) and np.all(np.signbit(vec1) == np.signbit(vec2))

match_count = 0
for x in routes:
    for v in base_routes:
        if exact_vector_match(x, v):
            match_count += 1
            break

match_percent = match_count / len(routes) * 100

# ░░ OUTPUT ░░
print("\nSample Generated Routes (first 8):")
for i, r in enumerate(routes[:8], 1):
    print(f"Route {i}: {np.round(r, 3)}")

print(f"\n✅ Match to valid route (signed 0 aware): {match_percent:.2f}%")

import torch
import torch.nn as nn
import torch.optim as optim
import random
import numpy as np
from torch.utils.data import DataLoader, TensorDataset

# Reproducibility
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Real valid routes as training data
valid_routes = [
        [ 0,  1,  2, 0],
    [ 1,  2,  0, 1 ],
    [ 2,  0,  1, 2 ],
    [0, 2, 1, 0 ],
    [1, 0, 2, 1 ],
    [2, 1, 0, 2 ]
]


# Convert real data to tensors
valid_routes_tensor = torch.tensor(valid_routes, dtype=torch.float32).to(device)

# Hyperparameters
input_size = 5
hidden_size = 128
output_size = 4
num_epochs = 11600
batch_size = 4
learning_rate = 0.000085
critic_iterations = 5
lambda_gp = 10.0

# Generator model
class Generator(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(True),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(True),
            nn.Linear(hidden_size, output_size)
        )

    def forward(self, x):
        return self.main(x)

# Critic model (no sigmoid)
class Critic(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(Critic, self).__init__()
        self.main = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(True),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(True),
            nn.Linear(hidden_size, 1)
        )

    def forward(self, x):
        return self.main(x)

# Prepare dataset
dataset = TensorDataset(valid_routes_tensor)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)

# Initialize models
generator = Generator(input_size, hidden_size, output_size).to(device)
critic = Critic(output_size, hidden_size).to(device)

# Optimizers
g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.9))
c_optimizer = optim.Adam(critic.parameters(), lr=learning_rate, betas=(0.5, 0.9))

# Gradient penalty function
def gradient_penalty(critic, real_data, fake_data):
    batch_size = real_data.size(0)
    alpha = torch.rand(batch_size, 1, device=device)
    alpha = alpha.expand_as(real_data)
    interpolates = alpha * real_data + (1 - alpha) * fake_data
    interpolates.requires_grad_(True)

    critic_interpolates = critic(interpolates)
    ones = torch.ones(critic_interpolates.size(), device=device)

    gradients = torch.autograd.grad(
        outputs=critic_interpolates,
        inputs=interpolates,
        grad_outputs=ones,
        create_graph=True,
        retain_graph=True,
        only_inputs=True
    )[0]

    gradients = gradients.view(batch_size, -1)
    gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean()
    return gp

# Training loop
def train_wgan():
    for epoch in range(num_epochs):
        for real_batch in dataloader:
            real_data = real_batch[0].to(device)
            batch_size_curr = real_data.size(0)

            # Train critic
            for _ in range(critic_iterations):
                noise = torch.randn(batch_size_curr, input_size, device=device)
                fake_data = generator(noise).detach()

                c_optimizer.zero_grad()
                # Wasserstein loss + gradient penalty
                loss_real = -critic(real_data).mean()
                loss_fake = critic(fake_data).mean()
                gp = gradient_penalty(critic, real_data, fake_data)
                c_loss = loss_real + loss_fake + lambda_gp * gp
                c_loss.backward()
                c_optimizer.step()

            # Train generator
            g_optimizer.zero_grad()
            noise = torch.randn(batch_size_curr, input_size, device=device)
            fake_data = generator(noise)
            g_loss = -critic(fake_data).mean()
            g_loss.backward()
            g_optimizer.step()

        if epoch % 500 == 0:
            print(f"Epoch [{epoch}/{num_epochs}] - C Loss: {c_loss.item():.4f}, G Loss: {g_loss.item():.4f}")

# Start training
train_wgan()

# Snap function to nearest valid route
def snap_route_to_valid(route):
    route = np.array(route)
    best_perm, best_err = None, float('inf')
    for perm in valid_routes:
        err = np.mean(np.abs(route - np.array(perm)))
        if err < best_err:
            best_perm, best_err = perm, err
    return best_perm

# Generate and print routes
generated_routes = generator(torch.randn(8, input_size, device=device)).cpu().detach().numpy()
print("\nGenerated Routes after WGAN Training:")
for i, route in enumerate(generated_routes, 1):
    snapped = snap_route_to_valid(route)
    print(f"Route {i}: Generated: {np.round(route,4)} | Snapped: {snapped}")

    #87.40 WGAN 83.22% use this

import matplotlib.pyplot as plt
import numpy as np

# ──────────────────────────────────────────────
# 1. TRIANGLE GEOMETRY WITH COORDINATE LABELS
# ──────────────────────────────────────────────
nodes = {
    "J0": (0, 0),       # Bottom-left
    "J1": (300, 300),   # Top
    "J2": (600, 0)      # Bottom-right
}

def node_to_coordinate(v):
    """Map scalar value to triangle perimeter coordinates"""
    v = v % 3
    if 0 <= v <= 1:
        t = v
        (x0, y0), (x1, y1) = nodes["J0"], nodes["J1"]
    elif 1 < v <= 2:
        t = v - 1
        (x0, y0), (x1, y1) = nodes["J1"], nodes["J2"]
    else:
        t = v - 2
        (x0, y0), (x1, y1) = nodes["J2"], nodes["J0"]
    x = x0 + (x1 - x0) * t
    y = y0 + (y1 - y0) * t
    return round(x, 2), round(y, 2)

# ──────────────────────────────────────────────
# 2. PLOTTING WITH COORDINATE ANNOTATIONS
# ──────────────────────────────────────────────
plt.figure(figsize=(10, 10))

# Draw triangle perimeter
tri_x = [nodes["J0"][0], nodes["J1"][0], nodes["J2"][0], nodes["J0"][0]]
tri_y = [nodes["J0"][1], nodes["J1"][1], nodes["J2"][1], nodes["J0"][1]]
plt.plot(tri_x, tri_y, "k-", linewidth=3, label="Triangle Network")

# Plot nodes with coordinate labels
for label, (x, y) in nodes.items():
    plt.scatter(x, y, c='red', s=150, edgecolors='black', zorder=5)
    # Offset annotations based on node position
    x_offset = 40 if label == "J2" else -40 if label == "J0" else 0
    y_offset = 40 if label == "J1" else -40 if label == "J0" else 0
    plt.annotate(f"{label} ({x}, {y})",
                 (x + x_offset, y + y_offset),
                 fontsize=12,
                 ha='center',
                 bbox=dict(facecolor="white", alpha=0.8, edgecolor="none"))

# Formatting
plt.title("Triangle Network with Coordinate Labels", fontsize=14, pad=15)
plt.xlabel("X position")
plt.ylabel("Y position")
plt.grid(True, linestyle="--", alpha=0.5)
plt.axis("equal")
plt.xlim(-100, 700)
plt.ylim(-100, 400)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# MAE values
gan_names = ['GAN 1', 'GAN 2', 'GAN 3']
triangle_gan_mae = [82.27, 84.75, 89.89]
triangle_wgan_mae =  [80.91, 83.22, 87.40]


# Bar position settings
x = np.arange(len(gan_names))
bar_width = 0.35

# Create plot
fig, ax = plt.subplots(figsize=(8, 5))
bar1 = ax.bar(x - bar_width/2, triangle_gan_mae, bar_width, label='Triangle WGAN', color='blue')
bar2 = ax.bar(x + bar_width/2, triangle_wgan_mae, bar_width, label='Box WGAN', color='teal')

# Labels and styling
ax.set_xlabel('Model')
ax.set_ylabel('Accuracy (%)')
ax.set_title('Accuracy: Triangle WGAN vs Box WGAN')
ax.set_xticks(x)
ax.set_xticklabels(gan_names)
ax.set_ylim(50, 100)
ax.legend()

# Add value labels on top of bars
for bars in [bar1, bar2]:
    for bar in bars:
        height = bar.get_height()
        ax.annotate(f'{height:.3f}',
                    xy=(bar.get_x() + bar.get_width() / 2, height),
                    xytext=(0, 3),  # offset text slightly above the bar
                    textcoords="offset points",
                    ha='center', va='bottom')

# Show plot
plt.tight_layout()
plt.show()